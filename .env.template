# -----------------------------------------------------------------------------
# API Keys
# -----------------------------------------------------------------------------

# LLNL LivAI API key (preferred for hosted models: Claude / GPT)
LIVAI_API_KEY=your_livai_key_here

# Optional: some libraries expect OPENAI_API_KEY
# If set, it may be treated as an alias for LIVAI_API_KEY
OPENAI_API_KEY=

# -----------------------------------------------------------------------------
# LLM backend selection
# -----------------------------------------------------------------------------

# Select which backend to use:
#   - "ollama" : local LLaMA models via Ollama (default, offline)
#   - "livai"  : LLNL LivAI gateway (Claude / GPT models)
LLM_BACKEND=ollama

# -----------------------------------------------------------------------------
# Model selection
# -----------------------------------------------------------------------------

# Model name to use for the selected backend
#
# Ollama examples (local, provenance-safe):
#   - "llama3.1:8b"    (recommended for ~16 GB RAM)
#   - "llama3.1:70b"  (requires ≥32 GB RAM or substantial GPU VRAM)
#
# LivAI examples (exact names depend on LivAI configuration):
#   - "claude-3.5-sonnet"
#   - "gpt-4.1"
#   - "gpt-4o-mini"

LLM_MODEL=llama3.1:8b

# -----------------------------------------------------------------------------
# LLM behavior
# -----------------------------------------------------------------------------

# Controls randomness in model outputs
# 0.0–0.2  → deterministic, best for scientific reasoning (recommended)
# 0.3–0.5  → more exploratory
LLM_TEMPERATURE=0.1

# Maximum number of tokens generated per response
# Increase if responses are getting cut off
LLM_MAX_TOKENS=2048

# -----------------------------------------------------------------------------
# Backend-specific configuration
# -----------------------------------------------------------------------------

# Ollama OpenAI-compatible API endpoint
# Only used when LLM_BACKEND=ollama
OLLAMA_BASE_URL=http://localhost:11434/v1

# LivAI OpenAI-compatible API endpoint
# Only used when LLM_BACKEND=livai
LIVAI_BASE_URL=https://api.livai.llnl.gov/v1
